{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78ba21d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Using device: cuda\n",
      "Loading model from C:\\Users\\Kamil\\Desktop\\Coding\\WUM_PROJECT\\models\\test21\\model_step_1500.pth\n",
      "Warning: Loading checkpoint without options, using default parameters\n",
      "Model loaded from C:\\Users\\Kamil\\Desktop\\Coding\\WUM_PROJECT\\models\\test21\\model_step_1500.pth\n",
      "Testing on 10 samples from the dataset...\n",
      "================================================================================\n",
      "\n",
      "Sample 1:\n",
      "Sample rate: 16000 Hz\n",
      "Audio length: 35840 samples (2.24 seconds)\n",
      "Reference: 'DON T ASK ME TO CARRY AN OILY RAG LIKE THAT'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kamil\\Desktop\\Coding\\HuggingFace\\Agent\\lib\\site-packages\\torch\\nn\\modules\\conv.py:370: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\Convolution.cpp:1037.)\n",
      "  return F.conv1d(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: ''\n",
      "VQ Loss: 2.0000\n",
      "Simple WER: 1.0000\n",
      "Raw tokens (first 10): []\n",
      "Decoded tokens (first 10): []\n",
      "----------------------------------------\n",
      "\n",
      "Sample 2:\n",
      "Sample rate: 16000 Hz\n",
      "Audio length: 33485 samples (2.09 seconds)\n",
      "Reference: 'BY EATING YOGURT  YOU MAY LIVE LONGER'\n",
      "Prediction: ''\n",
      "VQ Loss: 2.0000\n",
      "Simple WER: 1.0000\n",
      "Raw tokens (first 10): []\n",
      "Decoded tokens (first 10): []\n",
      "----------------------------------------\n",
      "\n",
      "Sample 3:\n",
      "Sample rate: 16000 Hz\n",
      "Audio length: 48845 samples (3.05 seconds)\n",
      "Reference: 'THE OVERWEIGHT CHARMER COULD SLIP POISON INTO ANYONE S TEA'\n",
      "Prediction: ''\n",
      "VQ Loss: 2.0000\n",
      "Simple WER: 1.0000\n",
      "Raw tokens (first 10): []\n",
      "Decoded tokens (first 10): []\n",
      "----------------------------------------\n",
      "\n",
      "Sample 4:\n",
      "Sample rate: 16000 Hz\n",
      "Audio length: 58061 samples (3.63 seconds)\n",
      "Reference: 'HE PICKED UP NINE PAIRS OF SOCKS FOR EACH BROTHER'\n",
      "Prediction: ''\n",
      "VQ Loss: 2.0000\n",
      "Simple WER: 1.0000\n",
      "Raw tokens (first 10): []\n",
      "Decoded tokens (first 10): []\n",
      "----------------------------------------\n",
      "\n",
      "Sample 5:\n",
      "Sample rate: 16000 Hz\n",
      "Audio length: 48845 samples (3.05 seconds)\n",
      "Reference: 'THE OVERWEIGHT CHARMER COULD SLIP POISON INTO ANYONE S TEA'\n",
      "Prediction: ''\n",
      "VQ Loss: 2.0000\n",
      "Simple WER: 1.0000\n",
      "Raw tokens (first 10): []\n",
      "Decoded tokens (first 10): []\n",
      "----------------------------------------\n",
      "\n",
      "Sample 6:\n",
      "Sample rate: 16000 Hz\n",
      "Audio length: 75879 samples (4.74 seconds)\n",
      "Reference: 'THEN HE WOULD REALIZE THEY WERE REALLY THINGS THAT ONLY HE HIMSELF COULD THINK'\n",
      "Prediction: ''\n",
      "VQ Loss: 2.0000\n",
      "Simple WER: 1.0000\n",
      "Raw tokens (first 10): []\n",
      "Decoded tokens (first 10): []\n",
      "----------------------------------------\n",
      "\n",
      "Sample 7:\n",
      "Sample rate: 16000 Hz\n",
      "Audio length: 48845 samples (3.05 seconds)\n",
      "Reference: 'THE OVERWEIGHT CHARMER COULD SLIP POISON INTO ANYONE S TEA'\n",
      "Prediction: ''\n",
      "VQ Loss: 2.0000\n",
      "Simple WER: 1.0000\n",
      "Raw tokens (first 10): []\n",
      "Decoded tokens (first 10): []\n",
      "----------------------------------------\n",
      "\n",
      "Sample 8:\n",
      "Sample rate: 16000 Hz\n",
      "Audio length: 33485 samples (2.09 seconds)\n",
      "Reference: 'GET A CALICO CAT TO KEEP'\n",
      "Prediction: ''\n",
      "VQ Loss: 2.0000\n",
      "Simple WER: 1.0000\n",
      "Raw tokens (first 10): []\n",
      "Decoded tokens (first 10): []\n",
      "----------------------------------------\n",
      "\n",
      "Sample 9:\n",
      "Sample rate: 16000 Hz\n",
      "Audio length: 43111 samples (2.69 seconds)\n",
      "Reference: 'THEY REMAINED LIFELONG FRIENDS AND COMPANIONS'\n",
      "Prediction: ''\n",
      "VQ Loss: 2.0000\n",
      "Simple WER: 1.0000\n",
      "Raw tokens (first 10): []\n",
      "Decoded tokens (first 10): []\n",
      "----------------------------------------\n",
      "\n",
      "Sample 10:\n",
      "Sample rate: 16000 Hz\n",
      "Audio length: 33485 samples (2.09 seconds)\n",
      "Reference: 'GET A CALICO CAT TO KEEP'\n",
      "Prediction: ''\n",
      "VQ Loss: 2.0000\n",
      "Simple WER: 1.0000\n",
      "Raw tokens (first 10): []\n",
      "Decoded tokens (first 10): []\n",
      "----------------------------------------\n",
      "\n",
      "================================================================================\n",
      "SUMMARY\n",
      "================================================================================\n",
      "Average WER: 1.0000\n",
      "Average VQ Loss: 2.0000\n",
      "Samples processed: 10\n",
      "\n",
      "Best prediction (WER: 1.0000):\n",
      "  Reference: 'DON T ASK ME TO CARRY AN OILY RAG LIKE THAT'\n",
      "  Prediction: ''\n",
      "\n",
      "Worst prediction (WER: 1.0000):\n",
      "  Reference: 'GET A CALICO CAT TO KEEP'\n",
      "  Prediction: ''\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import datasets\n",
    "from dataset import get_tokenizer\n",
    "from transcribe_model import TranscribeModel\n",
    "\n",
    "def predict_on_idrak_dataset(model_path, num_samples=5, device='cuda'):\n",
    "    \"\"\"\n",
    "    Test the model on the idrak_timit_subsample1 dataset.\n",
    "    \n",
    "    Args:\n",
    "        model_path: Path to your trained model\n",
    "        num_samples: Number of samples to test\n",
    "        device: Device to use\n",
    "    \"\"\"\n",
    "    # Load dataset\n",
    "    print(\"Loading dataset...\")\n",
    "    dataset = datasets.load_dataset(\"m-aliabbas/idrak_timit_subsample1\", split=\"train\")\n",
    "    \n",
    "    # Load tokenizer and model\n",
    "    tokenizer = get_tokenizer()\n",
    "    blank_token = tokenizer.token_to_id(\"<□>\")\n",
    "    \n",
    "    device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Load model\n",
    "    try:\n",
    "        model = TranscribeModel.load(model_path).to(device)\n",
    "        model.eval()\n",
    "        print(f\"Model loaded from {model_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Testing on {num_samples} samples from the dataset...\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i in range(min(num_samples, len(dataset))):\n",
    "        # Get data sample\n",
    "        data = dataset[i]\n",
    "        audio = data[\"audio\"][\"array\"]\n",
    "        sample_rate = data[\"audio\"][\"sampling_rate\"]\n",
    "        transcription = data[\"transcription\"].upper()  # Convert to uppercase\n",
    "        \n",
    "        print(f\"\\nSample {i+1}:\")\n",
    "        print(f\"Sample rate: {sample_rate} Hz\")\n",
    "        print(f\"Audio length: {len(audio)} samples ({len(audio)/sample_rate:.2f} seconds)\")\n",
    "        print(f\"Reference: '{transcription}'\")\n",
    "        \n",
    "        # Preprocess audio\n",
    "        audio_tensor = torch.tensor(audio).float().unsqueeze(0).to(device)\n",
    "        \n",
    "        # Limit audio length to prevent memory issues\n",
    "        max_length = 80000  # 5 seconds at 16kHz\n",
    "        if audio_tensor.shape[1] > max_length:\n",
    "            audio_tensor = audio_tensor[:, :max_length]\n",
    "            print(f\"Audio truncated to {max_length} samples\")\n",
    "        \n",
    "        # Forward pass\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                output, vq_loss = model(audio_tensor)\n",
    "            \n",
    "            # Decode prediction\n",
    "            decoded_preds = greedy_decoder(output, blank_token=blank_token)\n",
    "            \n",
    "            # Convert tokens to text\n",
    "            if len(decoded_preds) > 0:\n",
    "                pred = decoded_preds[0]\n",
    "                tokens = []\n",
    "                for p in pred:\n",
    "                    if p < len(tokenizer.get_vocab()):\n",
    "                        token = tokenizer.id_to_token(p)\n",
    "                        # Use FIXED special token filtering\n",
    "                        if token and token not in [\"<pad>\", \"<unk>\", \"<s>\", \"</s>\", \"<□>\"]:\n",
    "                            tokens.append(token)\n",
    "                \n",
    "                prediction = \"\".join(tokens)\n",
    "                \n",
    "                # Calculate simple accuracy metrics\n",
    "                wer = calculate_simple_wer(prediction, transcription)\n",
    "                \n",
    "                print(f\"Prediction: '{prediction}'\")\n",
    "                print(f\"VQ Loss: {vq_loss.item():.4f}\")\n",
    "                print(f\"Simple WER: {wer:.4f}\")\n",
    "                \n",
    "                # Debug info\n",
    "                print(f\"Raw tokens (first 10): {pred[:10]}\")\n",
    "                print(f\"Decoded tokens (first 10): {tokens[:10]}\")\n",
    "                \n",
    "                results.append({\n",
    "                    'sample_id': i,\n",
    "                    'reference': transcription,\n",
    "                    'prediction': prediction,\n",
    "                    'wer': wer,\n",
    "                    'vq_loss': vq_loss.item(),\n",
    "                    'audio_length': len(audio)\n",
    "                })\n",
    "                \n",
    "            else:\n",
    "                print(\"Prediction: (empty)\")\n",
    "                results.append({\n",
    "                    'sample_id': i,\n",
    "                    'reference': transcription,\n",
    "                    'prediction': \"\",\n",
    "                    'wer': 1.0,\n",
    "                    'vq_loss': vq_loss.item(),\n",
    "                    'audio_length': len(audio)\n",
    "                })\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error during prediction: {e}\")\n",
    "            continue\n",
    "        \n",
    "        print(\"-\" * 40)\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if results:\n",
    "        avg_wer = sum(r['wer'] for r in results) / len(results)\n",
    "        avg_vq_loss = sum(r['vq_loss'] for r in results) / len(results)\n",
    "        \n",
    "        print(f\"Average WER: {avg_wer:.4f}\")\n",
    "        print(f\"Average VQ Loss: {avg_vq_loss:.4f}\")\n",
    "        print(f\"Samples processed: {len(results)}\")\n",
    "        \n",
    "        # Show best and worst predictions\n",
    "        results.sort(key=lambda x: x['wer'])\n",
    "        \n",
    "        print(f\"\\nBest prediction (WER: {results[0]['wer']:.4f}):\")\n",
    "        print(f\"  Reference: '{results[0]['reference']}'\")\n",
    "        print(f\"  Prediction: '{results[0]['prediction']}'\")\n",
    "        \n",
    "        print(f\"\\nWorst prediction (WER: {results[-1]['wer']:.4f}):\")\n",
    "        print(f\"  Reference: '{results[-1]['reference']}'\")\n",
    "        print(f\"  Prediction: '{results[-1]['prediction']}'\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def greedy_decoder(log_probs, blank_token=0):\n",
    "    \"\"\"Greedy decoder for CTC outputs.\"\"\"\n",
    "    predictions = torch.argmax(log_probs, dim=-1).cpu().numpy()\n",
    "    decoded_predictions = []\n",
    "    \n",
    "    for pred in predictions:\n",
    "        previous = -1\n",
    "        decoded_seq = []\n",
    "        for p in pred:\n",
    "            if p != previous and p != blank_token:\n",
    "                decoded_seq.append(p)\n",
    "            previous = p\n",
    "        decoded_predictions.append(decoded_seq)\n",
    "    \n",
    "    return decoded_predictions\n",
    "\n",
    "def calculate_simple_wer(prediction, reference):\n",
    "    \"\"\"Simple WER calculation.\"\"\"\n",
    "    pred_words = prediction.split()\n",
    "    ref_words = reference.split()\n",
    "    \n",
    "    if len(ref_words) == 0:\n",
    "        return 1.0 if len(pred_words) > 0 else 0.0\n",
    "    \n",
    "    # Simple edit distance\n",
    "    dp = [[0] * (len(ref_words) + 1) for _ in range(len(pred_words) + 1)]\n",
    "    \n",
    "    for i in range(len(pred_words) + 1):\n",
    "        dp[i][0] = i\n",
    "    for j in range(len(ref_words) + 1):\n",
    "        dp[0][j] = j\n",
    "    \n",
    "    for i in range(1, len(pred_words) + 1):\n",
    "        for j in range(1, len(ref_words) + 1):\n",
    "            if pred_words[i-1] == ref_words[j-1]:\n",
    "                dp[i][j] = dp[i-1][j-1]\n",
    "            else:\n",
    "                dp[i][j] = min(dp[i-1][j], dp[i][j-1], dp[i-1][j-1]) + 1\n",
    "    \n",
    "    return dp[len(pred_words)][len(ref_words)] / len(ref_words)\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    model_path = r\"C:\\Users\\Kamil\\Desktop\\Coding\\WUM_PROJECT\\models\\test21\\model_step_1500.pth\"\n",
    "    \n",
    "    # Test on 10 samples\n",
    "    results = predict_on_idrak_dataset(model_path, num_samples=10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
